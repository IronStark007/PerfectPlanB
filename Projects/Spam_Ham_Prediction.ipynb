{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introduction\n\nThe mobile server works on various models to classify the spam and ham (not spam) sms.\n\nThese models do text recognition and on the basis of recognition, models predicts whether to store the sms in spam folder or not.We will also build a such type of model today and see how data science play such a wonderful role in our daily life by separating unwanted messages in spam.\n\n### Problem\nSo our todays problem is to predicting spam mails through different Machine learning model.\n\n### Solution \nFirst, We will download the dataset from <a href='https://www.kaggle.com/uciml/sms-spam-collection-dataset' target='_blank'>Kaggle </a>.Then we will do the feature engineering or extraction and make the data in suitable form to do model building.We will split the datset into train and test. Finally, We will create different Machine Learning model to solve our spam predictions problem and then check\nthe choose the best model by comparing each model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Load the Dataset\nWe will import the pandas to load the dataset the we have downloaded"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importing pandas\nimport pandas as pd",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After importing the library, we will load the dataset using pandas attribute read_csv\n\n`Make sure that you have downloaded the dataset in the same folder in which our script is otherwise it will create an error.`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# loading the dataset (encoding is done due to file format is latin)\ndf=pd.read_csv('spam.csv',encoding='latin-1')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Analyzing\nAfter loading the dataset we will do the analysis on the data to make it suitable for our model\nSeeing the data by head attribute which will load the first 5 rows of our data "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Taking a glance at the data\ndf.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "     v1                                                 v2 Unnamed: 2  \\\n0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n1   ham                      Ok lar... Joking wif u oni...        NaN   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3   ham  U dun say so early hor... U c already then say...        NaN   \n4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "By seeing the data we can say that, the columns name is not in good format and there is other three rows namely 1.unnamed:2 2.unmaned:3 3.unnamed:4 which are having null values and not needed for analyzing so we will delete all the three rows one by one using del attribute "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# deleting unnamed:2\ndel df['Unnamed: 2']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# deleting unnamed:3\ndel df['Unnamed: 3']",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# deleting unnamed:4\ndel df['Unnamed: 4']",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After deleting the unwanted three columns we have to name our columns in specific format so that the dataset will be in good format. \nWe will do this by changing the name of column v1 to Result and v2 to Text by rename attribute."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# changing columns name\ndf.rename(columns={'v1':'Result','v2':'Text'},inplace=True)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Saving the dataset\nAfter transforming the dataset into suitable format we can save the dataset to do further analysis.\n`Note this step is optional but very important since we tranformed data in suitable form and now we can also share it to others if needed`\n\nSaving the data using to_csv attribute of pandas"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# saving the dataset (index=False is used to not creating another index during saving)\ndf.to_csv('spamham.csv',index=False)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After saving the dataset we dan load the new dataset through read_csv to do further analysis and model building"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# reading the new dataset or loading the new dataset\ndf=pd.read_csv('spamham.csv')",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After loading the new dataset we can print the first 5 rows of the dataset by using head"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# taking a look at the dataset\ndf.head()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "  Result                                               Text\n0    ham  Go until jurong point, crazy.. Available only ...\n1    ham                      Ok lar... Joking wif u oni...\n2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3    ham  U dun say so early hor... U c already then say...\n4    ham  Nah I don't think he goes to usf, he lives aro...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Result</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, the dataset is right format\nLets check the descriptive statistics of our data using describe attribute which will load the statistical analysis on the numerical dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# statistical analysis\ndf.describe()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "       Result                    Text\ncount    5572                    5572\nunique      2                    5169\ntop       ham  Sorry, I'll call later\nfreq     4825                      30",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Result</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5572</td>\n      <td>5572</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>5169</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4825</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There is two unique value in our dataset ham and spam in which ham having more in number i.e. 4825 keeping this in mind lets check the data type of the columns by using type attribute"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# printing the data types\ndf.dtypes",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Result    object\nText      object\ndtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Further we can tranform the result data type into numerical in which ham=0 and spam=1 to make the predicted more suitable"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# passing result columns in a for-loop to change the ham and spam in 0 and 1 respectively\nfor result in df['Result']:\n    if result=='ham':\n        df['Result']=df['Result'].replace('ham',0)\n    else:\n        df['Result']=df['Result'].replace('spam',1)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we can look at the changed result column"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# checking the result column\ndf['Result']",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "0       0\n1       0\n2       1\n3       0\n4       0\n       ..\n5567    1\n5568    0\n5569    0\n5570    0\n5571    0\nName: Result, Length: 5572, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# checking the changed data type of result\ndf.dtypes",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "Result     int64\nText      object\ndtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Train-Test Split\nNow, its time split the data into training and testing datset.\n\nIts a very important step of our model building. We have to split the data into train and test so that the model will train from the training dataset and then predict or test the model using test data and train data\nFirst, import the train test split from the sklearn library"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importing the train-test split package\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After importing the library we have to make X (independant variable) and Y (dependant variable) using our dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# initializing X and Y\nX=df['Text']\nY=df['Result']",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, we are good to split the data into train and test\n\nSplitting the data in ratio of 80-20 of train-test "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# splitting the dataset\nx_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8,test_size=0.2,random_state=3)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Feature Extraction \nWe cannot do the model building on the text data so we have the pull or extract the feature of the text on the basis of which our model will do the prediction \n\nWe will import the feature extraction libarary in which we will use TfidfVectorizer to extracting the feature from our data "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing feature extraction library\nfrom sklearn.feature_extraction.text import TfidfVectorizer as vector",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After importing feature_extraction, we will tranform our x_train and x_test data into x_train_features and x_test_features respectively in lowercase and initialise the stop words as english \n\n`Stop words means like various english letter which normally told us that whether the sms being arrived is ham or spam using words like \"Congratulation,Hurray,you won\" in ham\"`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# initializing the feature extraction as feature\nfeature=vector(min_df=1,lowercase=True,stop_words='english')",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now its time to tranfrom the data using fit_tranfrom attribute of vector"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#tranforming x_train\nx_train_features=feature.fit_transform(x_train)\n\n# tranforming x_test\nx_test_features=feature.transform(x_test)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using Support Vector Machine\nFinally, its time to load our model and build it then predict our model accuracy \n\nFirst, we will train our dataset using Support Vector Machine (SVM) model.Loading the model SVM using sklearn library\nand also importing the accuracy_score to check the accuracy of our model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importing SVM which is named as LinearSVC in sklearn\nfrom sklearn.svm import LinearSVC\n\n# importing accuracy score for checking accuracy\nfrom sklearn.metrics import accuracy_score",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now,initializing the SVM to do further analysis"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# initializing SVM as svm\nsvm=LinearSVC()",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Then fit the training set into our model to train the model using fit attribute"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Training the svm\nsvm.fit(x_train_features,y_train)",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "LinearSVC()"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "When the output shows the original Library means our model is fully trained using SVM\n\nFinally, Its time to predict or test the model using test data and by predict attribute and then checking the accuracy by comparing the true and predicted value using accuracy_score"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# testing the model on train data\ny_train_pred=svm.predict(x_train_features)\n\n# checking its accuracy\nacc_svm = accuracy_score(y_train,y_train_pred)\nprint(\"Accuracy score on train model :\",acc_svm)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy score on train model : 0.9995512676688355\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "SO our model gives 99% accuracy on our train data \n\nLets check the accuracy on the test data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# testing the model on test data\ny_test_pred=svm.predict(x_test_features)\nacc = accuracy_score(y_test,y_test_pred)\nprint(\"Accuracy score on train model :\",acc)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy score on train model : 0.9856502242152466\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So, our model gives 98% accuracy on our test data.\n# Validating model\nWe can validate our model by giving it a new data so as manually the accuracy of our model on new data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# giving new input\ninput=['I HAVE A DATE ON SUNDAY WITH WILL!!']",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "But the input will not be given to our model as it is since it is in raw format and we have to do feature extraction also so we have to convert our data using the feature extraction we initialzed up and then check the outcome using predict function of our model "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# tranforming the input using fit attribute\ninput_feature=feature.transform(input)\n\n# predicting the outcome\npred=svm.predict(input_feature)\nif pred[0]==1:\n    print('Spam Mail')\nelse:\n    print('Ham Mail')",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Ham Mail\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "SO, our model is going good on the new data.\n# Using K-Nearest Neighbour\nNow,lets check whether using KNearestNeighbour (KNN) will give us more accuracy or not\n\nFirst, we have to import the KNN which is a package of sklearn and then as usual we have to train our model and then predict or test it and then check accuracy.After all this, we will compare the accuracy of the both model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importing KNN\nfrom sklearn.neighbors import KNeighborsClassifier",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After importing we have to initialize the model with K=3\n\n`This is done because our model will predict the outcome based on its neighbour`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# initialising the model\nknn=KNeighborsClassifier(n_neighbors=3)",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Training the model using fit attribute. The output will print the model means it is successfuly trained"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# training our model\nknn.fit(x_train_features,y_train)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "KNeighborsClassifier(n_neighbors=3)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And finally we have to test our model and check its accuracy by comparing true and predicted value\n "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Testing the model on train data\ny_train_pred=knn.predict(x_train_features)\n\n# checking its accuracy\nacc=accuracy_score(y_train,y_train_pred)\nprint(\"Accuracy on train score :\",acc)",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy on train score : 0.9450302894323536\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So, our KNN model gives 94% accuracy on test data which is comparatively less than SVM model \n\nLets check our accuracy on test data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# testing the model on test data\ny_test_pred=knn.predict(x_test_features)\n\n# checking its accuracy\nacc_knn=accuracy_score(y_test,y_test_pred)\nprint(\"Accuracy on train score :\",acc_knn)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy on train score : 0.9201793721973094\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So, our KNN model gives 92% accuracy on test data which is also less than SVM model \n# Validating model\nBut it is not a bad model since it gives more than 90% accuracy on test and train data. SO we can also validate this model by using a new input as a validation data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# giving a new input\ninput=['I HAVE A DATE ON SUNDAY WITH WILL!!']",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So we have to tranfrom this new input into suitable format using feature extraction which we had imported earlier"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# transforming new data for passing into the model\ninput_feature=feature.transform(input)\n\n# predicting the outcome\npred=knn.predict(input_feature)\nif pred[0]==1:\n    print('Spam Mail')\nelse:\n    print('Ham Mail')",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Ham Mail\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Conclusion\nSo our both model gives a good accuracy on new data but in comparison the SVM is leading \nIn this project, We have successfully build our model using SVM and KNN model of sklearn and solved our problem"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Thank You\nI want to thank you all for reading my post, I hope that now you can easily build a binary classification model using raw dataset. But if any problem occurs, contact me in comment section and any appreciation are also most welcome.\nThank You!!!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    },
    "gist": {
      "id": "",
      "data": {
        "description": "SpamPrediction.ipynb",
        "public": true
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
